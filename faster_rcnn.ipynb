{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROBOFLOW-tensorflow-object-detection-faster-rcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FIqnjbWYsuQw",
        "2FKFq8RXs6bs",
        "MFyCeiBb9BbS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewjgray/coralcam/blob/master/faster_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsT4-_Eq45Ww",
        "colab_type": "text"
      },
      "source": [
        "NOTE: to obtain the most recent version of this notebook, please copy from \n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1U3fkRu6-hwjk7wWIpg-iylL2u5T9t7rr#scrollTo=lsT4-_Eq45Ww)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "## **Training Faster R-CNN Object Detection on a Custom Dataset**\n",
        "\n",
        "### **Overview**\n",
        "\n",
        "This notebook walks through how to train a Faster R-CNN object detection model using the TensorFlow Object Detection API.\n",
        "\n",
        "In this specific example, we'll training an object detection model to recognize cells types: white blood cells, red blood cells and platelets. **To adapt this example to train on your own dataset, you only need to change two lines of code in this notebook.**\n",
        "\n",
        "Everything in this notebook is also hosted on this [GitHub repo](https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn).\n",
        "\n",
        "![Blood Cell Example](https://i.imgur.com/QwyX2aD.png)\n",
        "\n",
        "**Credit to [DLology](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) and [Tony607](https://github.com/Tony607)**, whom wrote the first notebook on which much of this is example is based. \n",
        "\n",
        "### **Our Data**\n",
        "\n",
        "We'll be using an open source cell dataset called BCCD (Blood Cell Count and Detection). Our dataset contains 364 images (and 4888 annotations!) is hosted publicly on Roboflow [here](https://public.roboflow.ai/object-detection/bccd).\n",
        "\n",
        "When adapting this example to your own data, create two datasets in Roboflow: `train` and `test`. Use Roboflow to generate TFRecords for each, replace their URLs in this notebook, and you're able to train on your own custom dataset.\n",
        "\n",
        "### **Our Model**\n",
        "\n",
        "We'll be training a Faster R-CNN neural network. Faster R-CNN is a two-stage detector: first it identifies regions of interest, and then passes these regions to a convolutional neural network. The outputted features maps are passed to a support vector machine (SVM) for classification. Regression between predicted bounding boxes and ground truth bounding boxes are computed. (Consider [this](https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a) deep dive for more!)\n",
        "\n",
        "The model arechitecture is one of many available via TensorFlow's [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        "\n",
        "### **Training**\n",
        "\n",
        "Google Colab provides free GPU resources. Click \"Runtime\" → \"Change runtime type\" → Hardware Accelerator dropdown to \"GPU.\"\n",
        "\n",
        "Colab does have memory limitations, and notebooks must be open in your browser to run. Sessions automatically clear themselves after 12 hours.\n",
        "\n",
        "### **Inference**\n",
        "\n",
        "We'll run inference directly in this notebook, and on three test images contained in the \"test\" folder from our GitHub repo. \n",
        "\n",
        "When adapting to your own dataset, you'll need to add test images to the `test` folder located at `tensorflow-object-detection/test`.\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.ai) makes managing, preprocessing, augmenting, and versioning datasets for computer vision seamless.\n",
        "\n",
        "Developers reduce 50% of their boilerplate code when using Roboflow's workflow, automate labelling quality assurance, save training time, and increase model reproducibility.\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW2W17o-p7SX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "be35972a-41e5-4fc2-daa5-2a2f611466ee"
      },
      "source": [
        "!pip install tensorflow_gpu==1.15"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 41kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.30.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==1.15) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_gpu==1.15) (47.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=606342689bbba5eabf2fb8c1a02b173d4dc21e0985af6382210dae4bb8d846f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 10000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1",
        "colab_type": "text"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a9b3efda-15f3-4fd9-eae5-6e4674ac44ab"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.84 MiB | 37.68 MiB/s, done.\n",
            "Resolving deltas: 100% (413/413), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "e206956b-9209-4a86-b082-f6a905c3b70d"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_test.py\", line 21, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 19, in <module>\n",
            "    from object_detection.builders import anchor_generator_builder\n",
            "  File \"/content/models/research/object_detection/builders/anchor_generator_builder.py\", line 23, in <module>\n",
            "    from object_detection.anchor_generators import flexible_grid_anchor_generator\n",
            "  File \"/content/models/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py\", line 19, in <module>\n",
            "    from object_detection.anchor_generators import grid_anchor_generator\n",
            "  File \"/content/models/research/object_detection/anchor_generators/grid_anchor_generator.py\", line 27, in <module>\n",
            "    from object_detection.utils import ops\n",
            "  File \"/content/models/research/object_detection/utils/ops.py\", line 28, in <module>\n",
            "    import tf_slim as slim\n",
            "ModuleNotFoundError: No module named 'tf_slim'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Roboflow automatically creates our TFRecord and label_map files that we need!\n",
        "\n",
        "**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n",
        "\n",
        "Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n",
        "\n",
        "To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfIPc5yxDOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0a40aa1-e565-488b-8ca6-14b5003ccef4"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb_FMcfnSbRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1b991d39-f0a0-4acc-b314-331346e1551c"
      },
      "source": [
        "# UPDATE THIS LINK - get our data from Roboflow\n",
        "!curl -L \"https://app.roboflow.ai/ds/2m90JAC3td?key=F097JxpZMN\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   891  100   891    0     0   1086      0 --:--:-- --:--:-- --:--:--  1085\n",
            "100 1145k  100 1145k    0     0  1130k      0  0:00:01  0:00:01 --:--:-- 1130k\n",
            "Archive:  roboflow.zip\n",
            " extracting: train/fish.tfrecord     \n",
            " extracting: test/fish.tfrecord      \n",
            " extracting: valid/fish.tfrecord     \n",
            " extracting: train/fish_label_map.pbtxt  \n",
            " extracting: test/fish_label_map.pbtxt  \n",
            " extracting: valid/fish_label_map.pbtxt  \n",
            " extracting: README.roboflow.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T58u1YP9sUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32906cb7-ed05-4e20-a071-9feda98106f1"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FYI.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qhOGaTTFsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "473b6f84-1908-4212-f01c-5fb3f7a954d0"
      },
      "source": [
        "# check out what we have in train\n",
        "%ls train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fish_label_map.pbtxt  fish.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnnSSBu_XXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d721b89-8957-4fcf-bc0d-23bf6c38a185"
      },
      "source": [
        "# show what we have in test\n",
        "%ls test"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fish_label_map.pbtxt  fish.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/valid/fish.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/fish.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/fish_label_map.pbtxt'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c965d356-1d70-47ba-d765-ff2c0da10a88"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e8c11566-58d9-4649-cef4-b75d5737c941"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 63 root   root 4.0K Jul  5 20:59 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0e3ffb5-26ed-477e-ba38-fc906a6bc25d"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a28af656-eb9a-4894-f0e8-dec7b273b778"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 1\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/fish.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/fish_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/valid/fish.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/fish_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF",
        "colab_type": "text"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f17c11c5-5f41-4315-9f41-a97696cc69e1"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-05 21:00:15--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 50.16.94.112, 3.229.170.137, 107.21.11.91, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|50.16.94.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  49.0MB/s    in 0.3s    \n",
            "\n",
            "2020-07-05 21:00:15 (49.0 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp",
        "colab_type": "text"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fa9b0b8-ffdf-4b24-e9ee-4a7a02edcf3e"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://94b259df5ada.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7_syR1SJ9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0b1d062a-3de2-400f-cbb9-8e215ea37600"
      },
      "source": [
        "pip install tf_slim"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71466ea4-bd77-4f18-a1ea-88c5d71a6582"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0705 21:02:33.464183 139647759361920 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0705 21:02:33.464391 139647759361920 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0705 21:02:33.464484 139647759361920 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0705 21:02:33.464565 139647759361920 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0705 21:02:33.464647 139647759361920 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0705 21:02:33.464718 139647759361920 config_util.py:552] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0705 21:02:33.464786 139647759361920 config_util.py:562] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0705 21:02:33.465529 139647759361920 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0705 21:02:33.465639 139647759361920 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01e899b0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0705 21:02:33.466034 139647759361920 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01e899b0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f01cdf5fea0>) includes params argument, but params are not passed to Estimator.\n",
            "W0705 21:02:33.466267 139647759361920 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f01cdf5fea0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0705 21:02:33.466912 139647759361920 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0705 21:02:33.467082 139647759361920 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0705 21:02:33.467317 139647759361920 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0705 21:02:33.473233 139647759361920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0705 21:02:33.502098 139647759361920 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0705 21:02:33.506749 139647759361920 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0705 21:02:33.525223 139647759361920 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0705 21:02:44.061704 139647759361920 deprecation.py:323] From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0705 21:02:44.160590 139647759361920 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0705 21:02:48.739954 139647759361920 deprecation.py:323] From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 21:02:52.588246 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0705 21:02:52.762318 139647759361920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:02:54.190357 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:02:54.202813 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 21:02:54.203213 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:428: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0705 21:03:00.068074 139647759361920 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:428: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0705 21:03:00.549963 139647759361920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:03:00.552150 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:03:00.566547 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "W0705 21:03:00.774515 139647759361920 variables_helper.py:153] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[360]], model variable shape: [[4]]. This variable will not be initialized from the checkpoint.\n",
            "W0705 21:03:00.774732 139647759361920 variables_helper.py:153] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 360]], model variable shape: [[1024, 4]]. This variable will not be initialized from the checkpoint.\n",
            "W0705 21:03:00.774826 139647759361920 variables_helper.py:153] Variable [SecondStageBoxPredictor/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[91]], model variable shape: [[2]]. This variable will not be initialized from the checkpoint.\n",
            "W0705 21:03:00.774910 139647759361920 variables_helper.py:153] Variable [SecondStageBoxPredictor/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 91]], model variable shape: [[1024, 2]]. This variable will not be initialized from the checkpoint.\n",
            "W0705 21:03:00.775652 139647759361920 variables_helper.py:156] Variable [global_step] is not available in checkpoint\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:347: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0705 21:03:03.919578 139647759361920 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:347: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 21:03:10.438929 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0705 21:03:10.440168 139647759361920 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 21:03:13.928449 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 21:03:13.928829: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-07-05 21:03:13.933110: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-07-05 21:03:13.933344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d0ff480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-05 21:03:13.933374: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-05 21:03:13.935346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-05 21:03:14.082928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:03:14.083634: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d0ff2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-05 21:03:14.083665: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-07-05 21:03:14.085143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:03:14.085654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 21:03:14.100353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:03:14.311537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:03:14.397786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 21:03:14.424240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 21:03:14.661177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 21:03:14.798507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 21:03:15.298860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 21:03:15.299140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:03:15.299786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:03:15.300294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 21:03:15.300425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:03:15.301755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 21:03:15.301787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 21:03:15.301798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 21:03:15.301953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:03:15.302551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:03:15.303143: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-05 21:03:15.303188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 21:03:18.970218 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 21:03:19.373977 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0705 21:03:29.790200 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-07-05 21:03:40.903556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:03:43.064671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 1.7086053, step = 0\n",
            "I0705 21:03:51.131005 139647759361920 basic_session_run_hooks.py:262] loss = 1.7086053, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.35959\n",
            "I0705 21:05:04.681668 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.35959\n",
            "INFO:tensorflow:loss = 0.7683148, step = 100 (73.552 sec)\n",
            "I0705 21:05:04.682744 139647759361920 basic_session_run_hooks.py:260] loss = 0.7683148, step = 100 (73.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50858\n",
            "I0705 21:06:10.969274 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50858\n",
            "INFO:tensorflow:loss = 0.6211666, step = 200 (66.288 sec)\n",
            "I0705 21:06:10.970642 139647759361920 basic_session_run_hooks.py:260] loss = 0.6211666, step = 200 (66.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51684\n",
            "I0705 21:07:16.895864 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51684\n",
            "INFO:tensorflow:loss = 0.49314997, step = 300 (65.926 sec)\n",
            "I0705 21:07:16.896920 139647759361920 basic_session_run_hooks.py:260] loss = 0.49314997, step = 300 (65.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51436\n",
            "I0705 21:08:22.930283 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51436\n",
            "INFO:tensorflow:loss = 0.32554662, step = 400 (66.035 sec)\n",
            "I0705 21:08:22.931477 139647759361920 basic_session_run_hooks.py:260] loss = 0.32554662, step = 400 (66.035 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51272\n",
            "I0705 21:09:29.036430 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51272\n",
            "INFO:tensorflow:loss = 0.21388981, step = 500 (66.106 sec)\n",
            "I0705 21:09:29.037590 139647759361920 basic_session_run_hooks.py:260] loss = 0.21388981, step = 500 (66.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51339\n",
            "I0705 21:10:35.113385 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51339\n",
            "INFO:tensorflow:loss = 0.31210616, step = 600 (66.077 sec)\n",
            "I0705 21:10:35.114594 139647759361920 basic_session_run_hooks.py:260] loss = 0.31210616, step = 600 (66.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50552\n",
            "I0705 21:11:41.535653 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50552\n",
            "INFO:tensorflow:loss = 0.24462694, step = 700 (66.422 sec)\n",
            "I0705 21:11:41.536779 139647759361920 basic_session_run_hooks.py:260] loss = 0.24462694, step = 700 (66.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51689\n",
            "I0705 21:12:47.460006 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51689\n",
            "INFO:tensorflow:loss = 0.1214087, step = 800 (65.925 sec)\n",
            "I0705 21:12:47.461281 139647759361920 basic_session_run_hooks.py:260] loss = 0.1214087, step = 800 (65.925 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 870 into training/model.ckpt.\n",
            "I0705 21:13:32.882546 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 870 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 21:13:35.671883 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:13:37.020549 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:13:37.033081 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 21:13:37.033462 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:13:37.919007 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:13:37.934091 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0705 21:13:38.994503 139647759361920 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0705 21:13:39.180632 139647759361920 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 21:13:39.680151 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T21:13:39Z\n",
            "I0705 21:13:39.695317 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T21:13:39Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 21:13:40.113482 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 21:13:40.114616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:13:40.115015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 21:13:40.115191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:13:40.115233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:13:40.115260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 21:13:40.115284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 21:13:40.115311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 21:13:40.115335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 21:13:40.115360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 21:13:40.115478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:13:40.115914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:13:40.116255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 21:13:40.116302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 21:13:40.116335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 21:13:40.116351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 21:13:40.116513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:13:40.116928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:13:40.117295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-870\n",
            "I0705 21:13:40.118252 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-870\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 21:13:41.094704 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 21:13:41.238940 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 21:13:44.480700 139645258036992 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 21:13:44.481164 139645258036992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 21:13:44.482655 139645258036992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.751\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.367\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-21:13:44\n",
            "I0705 21:13:44.939663 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-21:13:44\n",
            "INFO:tensorflow:Saving dict for global step 870: DetectionBoxes_Precision/mAP = 0.31169525, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.75148517, DetectionBoxes_Precision/mAP (small) = 0.19077903, DetectionBoxes_Precision/mAP@.50IOU = 0.7250571, DetectionBoxes_Precision/mAP@.75IOU = 0.22430243, DetectionBoxes_Recall/AR@1 = 0.19090909, DetectionBoxes_Recall/AR@10 = 0.4090909, DetectionBoxes_Recall/AR@100 = 0.43636364, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.36666667, Loss/BoxClassifierLoss/classification_loss = 0.034776054, Loss/BoxClassifierLoss/localization_loss = 0.044694018, Loss/RPNLoss/localization_loss = 0.040788893, Loss/RPNLoss/objectness_loss = 0.025675852, Loss/total_loss = 0.14593482, global_step = 870, learning_rate = 0.0002, loss = 0.14593482\n",
            "I0705 21:13:44.939970 139647759361920 estimator.py:2049] Saving dict for global step 870: DetectionBoxes_Precision/mAP = 0.31169525, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.75148517, DetectionBoxes_Precision/mAP (small) = 0.19077903, DetectionBoxes_Precision/mAP@.50IOU = 0.7250571, DetectionBoxes_Precision/mAP@.75IOU = 0.22430243, DetectionBoxes_Recall/AR@1 = 0.19090909, DetectionBoxes_Recall/AR@10 = 0.4090909, DetectionBoxes_Recall/AR@100 = 0.43636364, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.36666667, Loss/BoxClassifierLoss/classification_loss = 0.034776054, Loss/BoxClassifierLoss/localization_loss = 0.044694018, Loss/RPNLoss/localization_loss = 0.040788893, Loss/RPNLoss/objectness_loss = 0.025675852, Loss/total_loss = 0.14593482, global_step = 870, learning_rate = 0.0002, loss = 0.14593482\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 870: training/model.ckpt-870\n",
            "I0705 21:13:45.817460 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 870: training/model.ckpt-870\n",
            "INFO:tensorflow:global_step/sec: 1.26926\n",
            "I0705 21:14:06.245915 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.26926\n",
            "INFO:tensorflow:loss = 0.17705314, step = 900 (78.786 sec)\n",
            "I0705 21:14:06.247016 139647759361920 basic_session_run_hooks.py:260] loss = 0.17705314, step = 900 (78.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.52021\n",
            "I0705 21:15:12.026372 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.52021\n",
            "INFO:tensorflow:loss = 0.15059906, step = 1000 (65.781 sec)\n",
            "I0705 21:15:12.027611 139647759361920 basic_session_run_hooks.py:260] loss = 0.15059906, step = 1000 (65.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51703\n",
            "I0705 21:16:17.944464 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51703\n",
            "INFO:tensorflow:loss = 0.17233366, step = 1100 (65.918 sec)\n",
            "I0705 21:16:17.945620 139647759361920 basic_session_run_hooks.py:260] loss = 0.17233366, step = 1100 (65.918 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5118\n",
            "I0705 21:17:24.090615 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5118\n",
            "INFO:tensorflow:loss = 0.22329478, step = 1200 (66.146 sec)\n",
            "I0705 21:17:24.091900 139647759361920 basic_session_run_hooks.py:260] loss = 0.22329478, step = 1200 (66.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51227\n",
            "I0705 21:18:30.216414 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51227\n",
            "INFO:tensorflow:loss = 0.15329735, step = 1300 (66.126 sec)\n",
            "I0705 21:18:30.217564 139647759361920 basic_session_run_hooks.py:260] loss = 0.15329735, step = 1300 (66.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51434\n",
            "I0705 21:19:36.251675 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51434\n",
            "INFO:tensorflow:loss = 0.20446001, step = 1400 (66.035 sec)\n",
            "I0705 21:19:36.252920 139647759361920 basic_session_run_hooks.py:260] loss = 0.20446001, step = 1400 (66.035 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51409\n",
            "I0705 21:20:42.297909 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51409\n",
            "INFO:tensorflow:loss = 0.2226508, step = 1500 (66.046 sec)\n",
            "I0705 21:20:42.299008 139647759361920 basic_session_run_hooks.py:260] loss = 0.2226508, step = 1500 (66.046 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51398\n",
            "I0705 21:21:48.349067 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51398\n",
            "INFO:tensorflow:loss = 0.20691288, step = 1600 (66.051 sec)\n",
            "I0705 21:21:48.350429 139647759361920 basic_session_run_hooks.py:260] loss = 0.20691288, step = 1600 (66.051 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51386\n",
            "I0705 21:22:54.405378 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51386\n",
            "INFO:tensorflow:loss = 0.083134584, step = 1700 (66.056 sec)\n",
            "I0705 21:22:54.406520 139647759361920 basic_session_run_hooks.py:260] loss = 0.083134584, step = 1700 (66.056 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1760 into training/model.ckpt.\n",
            "I0705 21:23:33.263222 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 1760 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 21:23:35.786062 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:23:37.095533 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:23:37.108261 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 21:23:37.108593 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:23:37.990606 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:23:38.004981 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 21:23:39.470834 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T21:23:39Z\n",
            "I0705 21:23:39.485953 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T21:23:39Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 21:23:39.889027 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 21:23:39.889838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:23:39.890273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 21:23:39.890406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:23:39.890440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:23:39.890463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 21:23:39.890488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 21:23:39.890509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 21:23:39.890530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 21:23:39.890551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 21:23:39.890668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:23:39.891060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:23:39.891382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 21:23:39.891426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 21:23:39.891440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 21:23:39.891448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 21:23:39.891572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:23:39.891960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:23:39.892306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1760\n",
            "I0705 21:23:39.893268 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-1760\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 21:23:40.844095 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 21:23:40.989299 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 21:23:43.677160 139645258036992 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 21:23:43.677567 139645258036992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 21:23:43.678911 139645258036992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.664\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-21:23:44\n",
            "I0705 21:23:44.124656 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-21:23:44\n",
            "INFO:tensorflow:Saving dict for global step 1760: DetectionBoxes_Precision/mAP = 0.2897497, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.18309322, DetectionBoxes_Precision/mAP@.50IOU = 0.6636174, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.36363637, DetectionBoxes_Recall/AR@100 = 0.4090909, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.33333334, Loss/BoxClassifierLoss/classification_loss = 0.03655812, Loss/BoxClassifierLoss/localization_loss = 0.06208274, Loss/RPNLoss/localization_loss = 0.041128296, Loss/RPNLoss/objectness_loss = 0.020327756, Loss/total_loss = 0.1600969, global_step = 1760, learning_rate = 0.0002, loss = 0.1600969\n",
            "I0705 21:23:44.124948 139647759361920 estimator.py:2049] Saving dict for global step 1760: DetectionBoxes_Precision/mAP = 0.2897497, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.18309322, DetectionBoxes_Precision/mAP@.50IOU = 0.6636174, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.36363637, DetectionBoxes_Recall/AR@100 = 0.4090909, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.33333334, Loss/BoxClassifierLoss/classification_loss = 0.03655812, Loss/BoxClassifierLoss/localization_loss = 0.06208274, Loss/RPNLoss/localization_loss = 0.041128296, Loss/RPNLoss/objectness_loss = 0.020327756, Loss/total_loss = 0.1600969, global_step = 1760, learning_rate = 0.0002, loss = 0.1600969\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1760: training/model.ckpt-1760\n",
            "I0705 21:23:44.128046 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1760: training/model.ckpt-1760\n",
            "INFO:tensorflow:global_step/sec: 1.30127\n",
            "I0705 21:24:11.253251 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.30127\n",
            "INFO:tensorflow:loss = 0.15274563, step = 1800 (76.848 sec)\n",
            "I0705 21:24:11.254383 139647759361920 basic_session_run_hooks.py:260] loss = 0.15274563, step = 1800 (76.848 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51841\n",
            "I0705 21:25:17.111649 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51841\n",
            "INFO:tensorflow:loss = 0.1384151, step = 1900 (65.858 sec)\n",
            "I0705 21:25:17.112818 139647759361920 basic_session_run_hooks.py:260] loss = 0.1384151, step = 1900 (65.858 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51492\n",
            "I0705 21:26:23.121880 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51492\n",
            "INFO:tensorflow:loss = 0.21344644, step = 2000 (66.010 sec)\n",
            "I0705 21:26:23.123193 139647759361920 basic_session_run_hooks.py:260] loss = 0.21344644, step = 2000 (66.010 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50609\n",
            "I0705 21:27:29.518796 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50609\n",
            "INFO:tensorflow:loss = 0.14036173, step = 2100 (66.397 sec)\n",
            "I0705 21:27:29.520056 139647759361920 basic_session_run_hooks.py:260] loss = 0.14036173, step = 2100 (66.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51541\n",
            "I0705 21:28:35.507436 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51541\n",
            "INFO:tensorflow:loss = 0.13660063, step = 2200 (65.988 sec)\n",
            "I0705 21:28:35.508385 139647759361920 basic_session_run_hooks.py:260] loss = 0.13660063, step = 2200 (65.988 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51393\n",
            "I0705 21:29:41.560686 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51393\n",
            "INFO:tensorflow:loss = 0.06534692, step = 2300 (66.053 sec)\n",
            "I0705 21:29:41.561769 139647759361920 basic_session_run_hooks.py:260] loss = 0.06534692, step = 2300 (66.053 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51471\n",
            "I0705 21:30:47.579998 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51471\n",
            "INFO:tensorflow:loss = 0.072154485, step = 2400 (66.019 sec)\n",
            "I0705 21:30:47.581078 139647759361920 basic_session_run_hooks.py:260] loss = 0.072154485, step = 2400 (66.019 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51264\n",
            "I0705 21:31:53.689470 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51264\n",
            "INFO:tensorflow:loss = 0.060156353, step = 2500 (66.109 sec)\n",
            "I0705 21:31:53.690568 139647759361920 basic_session_run_hooks.py:260] loss = 0.060156353, step = 2500 (66.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5186\n",
            "I0705 21:32:59.539556 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5186\n",
            "INFO:tensorflow:loss = 0.1057952, step = 2600 (65.850 sec)\n",
            "I0705 21:32:59.540871 139647759361920 basic_session_run_hooks.py:260] loss = 0.1057952, step = 2600 (65.850 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2652 into training/model.ckpt.\n",
            "I0705 21:33:33.281724 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 2652 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 21:33:35.821509 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:33:37.189408 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:33:37.202031 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 21:33:37.202383 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:33:38.511502 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:33:38.526141 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 21:33:40.028922 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T21:33:40Z\n",
            "I0705 21:33:40.045549 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T21:33:40Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 21:33:40.451467 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 21:33:40.452196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:33:40.452597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 21:33:40.452693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:33:40.452720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:33:40.452747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 21:33:40.452780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 21:33:40.452805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 21:33:40.452836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 21:33:40.452866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 21:33:40.452980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:33:40.453432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:33:40.453797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 21:33:40.453839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 21:33:40.453852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 21:33:40.453861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 21:33:40.453978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:33:40.454379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:33:40.454694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2652\n",
            "I0705 21:33:40.455768 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-2652\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 21:33:41.488270 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 21:33:41.639762 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 21:33:44.423783 139645372360448 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 21:33:44.425209 139645372360448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 21:33:44.426895 139645372360448 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-21:33:44\n",
            "I0705 21:33:44.868832 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-21:33:44\n",
            "INFO:tensorflow:Saving dict for global step 2652: DetectionBoxes_Precision/mAP = 0.259791, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.14908534, DetectionBoxes_Precision/mAP@.50IOU = 0.6543605, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.03920865, Loss/BoxClassifierLoss/localization_loss = 0.053342067, Loss/RPNLoss/localization_loss = 0.042850547, Loss/RPNLoss/objectness_loss = 0.02011004, Loss/total_loss = 0.1555113, global_step = 2652, learning_rate = 0.0002, loss = 0.1555113\n",
            "I0705 21:33:44.869109 139647759361920 estimator.py:2049] Saving dict for global step 2652: DetectionBoxes_Precision/mAP = 0.259791, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.14908534, DetectionBoxes_Precision/mAP@.50IOU = 0.6543605, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.03920865, Loss/BoxClassifierLoss/localization_loss = 0.053342067, Loss/RPNLoss/localization_loss = 0.042850547, Loss/RPNLoss/objectness_loss = 0.02011004, Loss/total_loss = 0.1555113, global_step = 2652, learning_rate = 0.0002, loss = 0.1555113\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2652: training/model.ckpt-2652\n",
            "I0705 21:33:44.872065 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2652: training/model.ckpt-2652\n",
            "INFO:tensorflow:global_step/sec: 1.28492\n",
            "I0705 21:34:17.365169 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.28492\n",
            "INFO:tensorflow:loss = 0.07293712, step = 2700 (77.825 sec)\n",
            "I0705 21:34:17.366251 139647759361920 basic_session_run_hooks.py:260] loss = 0.07293712, step = 2700 (77.825 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50613\n",
            "I0705 21:35:23.760379 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50613\n",
            "INFO:tensorflow:loss = 0.10403134, step = 2800 (66.395 sec)\n",
            "I0705 21:35:23.761560 139647759361920 basic_session_run_hooks.py:260] loss = 0.10403134, step = 2800 (66.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51661\n",
            "I0705 21:36:29.696865 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51661\n",
            "INFO:tensorflow:loss = 0.08069777, step = 2900 (65.936 sec)\n",
            "I0705 21:36:29.698018 139647759361920 basic_session_run_hooks.py:260] loss = 0.08069777, step = 2900 (65.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51027\n",
            "I0705 21:37:35.910338 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51027\n",
            "INFO:tensorflow:loss = 0.1115508, step = 3000 (66.214 sec)\n",
            "I0705 21:37:35.911620 139647759361920 basic_session_run_hooks.py:260] loss = 0.1115508, step = 3000 (66.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51348\n",
            "I0705 21:38:41.983225 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51348\n",
            "INFO:tensorflow:loss = 0.07341997, step = 3100 (66.073 sec)\n",
            "I0705 21:38:41.984308 139647759361920 basic_session_run_hooks.py:260] loss = 0.07341997, step = 3100 (66.073 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51232\n",
            "I0705 21:39:48.106863 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51232\n",
            "INFO:tensorflow:loss = 0.09078644, step = 3200 (66.124 sec)\n",
            "I0705 21:39:48.108172 139647759361920 basic_session_run_hooks.py:260] loss = 0.09078644, step = 3200 (66.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51334\n",
            "I0705 21:40:54.185864 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51334\n",
            "INFO:tensorflow:loss = 0.07192022, step = 3300 (66.079 sec)\n",
            "I0705 21:40:54.187036 139647759361920 basic_session_run_hooks.py:260] loss = 0.07192022, step = 3300 (66.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50565\n",
            "I0705 21:42:00.602317 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50565\n",
            "INFO:tensorflow:loss = 0.025695745, step = 3400 (66.417 sec)\n",
            "I0705 21:42:00.603620 139647759361920 basic_session_run_hooks.py:260] loss = 0.025695745, step = 3400 (66.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50374\n",
            "I0705 21:43:07.103286 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50374\n",
            "INFO:tensorflow:loss = 0.0757697, step = 3500 (66.501 sec)\n",
            "I0705 21:43:07.104348 139647759361920 basic_session_run_hooks.py:260] loss = 0.0757697, step = 3500 (66.501 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3541 into training/model.ckpt.\n",
            "I0705 21:43:33.463720 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 3541 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 21:43:36.003987 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:43:37.344543 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:43:37.357570 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 21:43:37.357946 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:43:38.260357 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:43:38.275027 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 21:43:39.764109 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T21:43:39Z\n",
            "I0705 21:43:39.781905 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T21:43:39Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 21:43:40.201189 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 21:43:40.202008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:43:40.202442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 21:43:40.202595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:43:40.202627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:43:40.202652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 21:43:40.202674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 21:43:40.202699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 21:43:40.202722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 21:43:40.202747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 21:43:40.202883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:43:40.203307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:43:40.203623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 21:43:40.203667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 21:43:40.203681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 21:43:40.203690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 21:43:40.203810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:43:40.204208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:43:40.204530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3541\n",
            "I0705 21:43:40.205585 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-3541\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 21:43:41.224505 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 21:43:41.373981 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 21:43:44.118395 139645372360448 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 21:43:44.118745 139645372360448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 21:43:44.120277 139645372360448 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-21:43:44\n",
            "I0705 21:43:44.566426 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-21:43:44\n",
            "INFO:tensorflow:Saving dict for global step 3541: DetectionBoxes_Precision/mAP = 0.26800075, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.1567038, DetectionBoxes_Precision/mAP@.50IOU = 0.64394516, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.33636364, DetectionBoxes_Recall/AR@100 = 0.33636364, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.24444444, Loss/BoxClassifierLoss/classification_loss = 0.047956116, Loss/BoxClassifierLoss/localization_loss = 0.05258327, Loss/RPNLoss/localization_loss = 0.043211512, Loss/RPNLoss/objectness_loss = 0.019594794, Loss/total_loss = 0.1633457, global_step = 3541, learning_rate = 0.0002, loss = 0.1633457\n",
            "I0705 21:43:44.566706 139647759361920 estimator.py:2049] Saving dict for global step 3541: DetectionBoxes_Precision/mAP = 0.26800075, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.1567038, DetectionBoxes_Precision/mAP@.50IOU = 0.64394516, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.33636364, DetectionBoxes_Recall/AR@100 = 0.33636364, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.24444444, Loss/BoxClassifierLoss/classification_loss = 0.047956116, Loss/BoxClassifierLoss/localization_loss = 0.05258327, Loss/RPNLoss/localization_loss = 0.043211512, Loss/RPNLoss/objectness_loss = 0.019594794, Loss/total_loss = 0.1633457, global_step = 3541, learning_rate = 0.0002, loss = 0.1633457\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3541: training/model.ckpt-3541\n",
            "I0705 21:43:44.569868 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3541: training/model.ckpt-3541\n",
            "INFO:tensorflow:global_step/sec: 1.29845\n",
            "I0705 21:44:24.118451 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.29845\n",
            "INFO:tensorflow:loss = 0.06406649, step = 3600 (77.016 sec)\n",
            "I0705 21:44:24.119963 139647759361920 basic_session_run_hooks.py:260] loss = 0.06406649, step = 3600 (77.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51198\n",
            "I0705 21:45:30.256757 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51198\n",
            "INFO:tensorflow:loss = 0.08227868, step = 3700 (66.138 sec)\n",
            "I0705 21:45:30.258000 139647759361920 basic_session_run_hooks.py:260] loss = 0.08227868, step = 3700 (66.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51152\n",
            "I0705 21:46:36.415506 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51152\n",
            "INFO:tensorflow:loss = 0.07849148, step = 3800 (66.159 sec)\n",
            "I0705 21:46:36.416546 139647759361920 basic_session_run_hooks.py:260] loss = 0.07849148, step = 3800 (66.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50919\n",
            "I0705 21:47:42.676153 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50919\n",
            "INFO:tensorflow:loss = 0.055405356, step = 3900 (66.261 sec)\n",
            "I0705 21:47:42.677213 139647759361920 basic_session_run_hooks.py:260] loss = 0.055405356, step = 3900 (66.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51036\n",
            "I0705 21:48:48.885453 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51036\n",
            "INFO:tensorflow:loss = 0.09300916, step = 4000 (66.209 sec)\n",
            "I0705 21:48:48.886562 139647759361920 basic_session_run_hooks.py:260] loss = 0.09300916, step = 4000 (66.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51365\n",
            "I0705 21:49:54.950977 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51365\n",
            "INFO:tensorflow:loss = 0.056506004, step = 4100 (66.066 sec)\n",
            "I0705 21:49:54.952714 139647759361920 basic_session_run_hooks.py:260] loss = 0.056506004, step = 4100 (66.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51142\n",
            "I0705 21:51:01.114046 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51142\n",
            "INFO:tensorflow:loss = 0.033040453, step = 4200 (66.162 sec)\n",
            "I0705 21:51:01.114964 139647759361920 basic_session_run_hooks.py:260] loss = 0.033040453, step = 4200 (66.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50959\n",
            "I0705 21:52:07.357139 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50959\n",
            "INFO:tensorflow:loss = 0.09817645, step = 4300 (66.243 sec)\n",
            "I0705 21:52:07.358044 139647759361920 basic_session_run_hooks.py:260] loss = 0.09817645, step = 4300 (66.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50683\n",
            "I0705 21:53:13.721726 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50683\n",
            "INFO:tensorflow:loss = 0.06450313, step = 4400 (66.365 sec)\n",
            "I0705 21:53:13.723040 139647759361920 basic_session_run_hooks.py:260] loss = 0.06450313, step = 4400 (66.365 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4431 into training/model.ckpt.\n",
            "I0705 21:53:33.477300 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 4431 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0705 21:53:33.596076 139647759361920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 21:53:36.038623 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:53:37.795603 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:53:37.808601 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 21:53:37.809007 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:53:38.728578 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 21:53:38.743916 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 21:53:40.267790 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T21:53:40Z\n",
            "I0705 21:53:40.283054 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T21:53:40Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 21:53:40.699452 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 21:53:40.700190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:53:40.700594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 21:53:40.700684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 21:53:40.700709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 21:53:40.700731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 21:53:40.700753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 21:53:40.700775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 21:53:40.700795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 21:53:40.700816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 21:53:40.700924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:53:40.701379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:53:40.701684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 21:53:40.701725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 21:53:40.701738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 21:53:40.701747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 21:53:40.701858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:53:40.702251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 21:53:40.702581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4431\n",
            "I0705 21:53:40.704715 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-4431\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 21:53:41.767290 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 21:53:41.937378 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 21:53:44.771619 139645372360448 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 21:53:44.771996 139645372360448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 21:53:44.772887 139645372360448 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.720\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-21:53:45\n",
            "I0705 21:53:45.238005 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-21:53:45\n",
            "INFO:tensorflow:Saving dict for global step 4431: DetectionBoxes_Precision/mAP = 0.27092263, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.16969652, DetectionBoxes_Precision/mAP@.50IOU = 0.72026986, DetectionBoxes_Precision/mAP@.75IOU = 0.27722773, DetectionBoxes_Recall/AR@1 = 0.21818182, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.050293274, Loss/BoxClassifierLoss/localization_loss = 0.056755167, Loss/RPNLoss/localization_loss = 0.044182982, Loss/RPNLoss/objectness_loss = 0.019988, Loss/total_loss = 0.17121942, global_step = 4431, learning_rate = 0.0002, loss = 0.17121942\n",
            "I0705 21:53:45.238303 139647759361920 estimator.py:2049] Saving dict for global step 4431: DetectionBoxes_Precision/mAP = 0.27092263, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.16969652, DetectionBoxes_Precision/mAP@.50IOU = 0.72026986, DetectionBoxes_Precision/mAP@.75IOU = 0.27722773, DetectionBoxes_Recall/AR@1 = 0.21818182, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.050293274, Loss/BoxClassifierLoss/localization_loss = 0.056755167, Loss/RPNLoss/localization_loss = 0.044182982, Loss/RPNLoss/objectness_loss = 0.019988, Loss/total_loss = 0.17121942, global_step = 4431, learning_rate = 0.0002, loss = 0.17121942\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4431: training/model.ckpt-4431\n",
            "I0705 21:53:45.241233 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4431: training/model.ckpt-4431\n",
            "INFO:tensorflow:global_step/sec: 1.2811\n",
            "I0705 21:54:31.779545 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.2811\n",
            "INFO:tensorflow:loss = 0.026473895, step = 4500 (78.058 sec)\n",
            "I0705 21:54:31.780732 139647759361920 basic_session_run_hooks.py:260] loss = 0.026473895, step = 4500 (78.058 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5115\n",
            "I0705 21:55:37.939160 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5115\n",
            "INFO:tensorflow:loss = 0.040594727, step = 4600 (66.159 sec)\n",
            "I0705 21:55:37.940177 139647759361920 basic_session_run_hooks.py:260] loss = 0.040594727, step = 4600 (66.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5127\n",
            "I0705 21:56:44.045982 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5127\n",
            "INFO:tensorflow:loss = 0.06901643, step = 4700 (66.107 sec)\n",
            "I0705 21:56:44.047199 139647759361920 basic_session_run_hooks.py:260] loss = 0.06901643, step = 4700 (66.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50566\n",
            "I0705 21:57:50.461999 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50566\n",
            "INFO:tensorflow:loss = 0.06302525, step = 4800 (66.416 sec)\n",
            "I0705 21:57:50.463339 139647759361920 basic_session_run_hooks.py:260] loss = 0.06302525, step = 4800 (66.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51101\n",
            "I0705 21:58:56.642697 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51101\n",
            "INFO:tensorflow:loss = 0.03490297, step = 4900 (66.181 sec)\n",
            "I0705 21:58:56.643910 139647759361920 basic_session_run_hooks.py:260] loss = 0.03490297, step = 4900 (66.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5104\n",
            "I0705 22:00:02.850154 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5104\n",
            "INFO:tensorflow:loss = 0.05454889, step = 5000 (66.207 sec)\n",
            "I0705 22:00:02.851408 139647759361920 basic_session_run_hooks.py:260] loss = 0.05454889, step = 5000 (66.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51022\n",
            "I0705 22:01:09.065531 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51022\n",
            "INFO:tensorflow:loss = 0.06661265, step = 5100 (66.215 sec)\n",
            "I0705 22:01:09.066551 139647759361920 basic_session_run_hooks.py:260] loss = 0.06661265, step = 5100 (66.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51169\n",
            "I0705 22:02:15.216660 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51169\n",
            "INFO:tensorflow:loss = 0.052675135, step = 5200 (66.151 sec)\n",
            "I0705 22:02:15.217803 139647759361920 basic_session_run_hooks.py:260] loss = 0.052675135, step = 5200 (66.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51039\n",
            "I0705 22:03:21.424947 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51039\n",
            "INFO:tensorflow:loss = 0.050967675, step = 5300 (66.209 sec)\n",
            "I0705 22:03:21.427079 139647759361920 basic_session_run_hooks.py:260] loss = 0.050967675, step = 5300 (66.209 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5320 into training/model.ckpt.\n",
            "I0705 22:03:34.028924 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 5320 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:03:36.589616 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:03:37.931960 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:03:37.944465 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:03:37.944808 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:03:38.819801 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:03:38.834183 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:03:40.311748 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:03:40Z\n",
            "I0705 22:03:40.326689 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:03:40Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:03:40.729427 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:03:40.730156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:03:40.730567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:03:40.730703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:03:40.730733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:03:40.730759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:03:40.730782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:03:40.730803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:03:40.730824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:03:40.730844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:03:40.730960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:03:40.731414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:03:40.731722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:03:40.731798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:03:40.731813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:03:40.731822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:03:40.731937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:03:40.732346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:03:40.732661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5320\n",
            "I0705 22:03:40.733647 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-5320\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:03:41.752231 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:03:41.917946 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:03:44.817648 139645372360448 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:03:44.818027 139645372360448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:03:44.819674 139645372360448 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.647\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:03:45\n",
            "I0705 22:03:45.090996 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:03:45\n",
            "INFO:tensorflow:Saving dict for global step 5320: DetectionBoxes_Precision/mAP = 0.25781742, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.15572058, DetectionBoxes_Precision/mAP@.50IOU = 0.6474812, DetectionBoxes_Precision/mAP@.75IOU = 0.27722773, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.3272727, DetectionBoxes_Recall/AR@100 = 0.3272727, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.23333333, Loss/BoxClassifierLoss/classification_loss = 0.059425198, Loss/BoxClassifierLoss/localization_loss = 0.06473752, Loss/RPNLoss/localization_loss = 0.045115832, Loss/RPNLoss/objectness_loss = 0.020561596, Loss/total_loss = 0.18984012, global_step = 5320, learning_rate = 0.0002, loss = 0.18984012\n",
            "I0705 22:03:45.091305 139647759361920 estimator.py:2049] Saving dict for global step 5320: DetectionBoxes_Precision/mAP = 0.25781742, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.15572058, DetectionBoxes_Precision/mAP@.50IOU = 0.6474812, DetectionBoxes_Precision/mAP@.75IOU = 0.27722773, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.3272727, DetectionBoxes_Recall/AR@100 = 0.3272727, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.23333333, Loss/BoxClassifierLoss/classification_loss = 0.059425198, Loss/BoxClassifierLoss/localization_loss = 0.06473752, Loss/RPNLoss/localization_loss = 0.045115832, Loss/RPNLoss/objectness_loss = 0.020561596, Loss/total_loss = 0.18984012, global_step = 5320, learning_rate = 0.0002, loss = 0.18984012\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5320: training/model.ckpt-5320\n",
            "I0705 22:03:45.094164 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5320: training/model.ckpt-5320\n",
            "INFO:tensorflow:global_step/sec: 1.29458\n",
            "I0705 22:04:38.670166 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.29458\n",
            "INFO:tensorflow:loss = 0.056359895, step = 5400 (77.244 sec)\n",
            "I0705 22:04:38.671318 139647759361920 basic_session_run_hooks.py:260] loss = 0.056359895, step = 5400 (77.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50858\n",
            "I0705 22:05:44.957690 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50858\n",
            "INFO:tensorflow:loss = 0.035598654, step = 5500 (66.287 sec)\n",
            "I0705 22:05:44.958777 139647759361920 basic_session_run_hooks.py:260] loss = 0.035598654, step = 5500 (66.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51502\n",
            "I0705 22:06:50.963379 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51502\n",
            "INFO:tensorflow:loss = 0.048254892, step = 5600 (66.006 sec)\n",
            "I0705 22:06:50.964308 139647759361920 basic_session_run_hooks.py:260] loss = 0.048254892, step = 5600 (66.006 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50491\n",
            "I0705 22:07:57.412380 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50491\n",
            "INFO:tensorflow:loss = 0.021383388, step = 5700 (66.449 sec)\n",
            "I0705 22:07:57.413552 139647759361920 basic_session_run_hooks.py:260] loss = 0.021383388, step = 5700 (66.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51654\n",
            "I0705 22:09:03.352002 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51654\n",
            "INFO:tensorflow:loss = 0.021908157, step = 5800 (65.940 sec)\n",
            "I0705 22:09:03.353247 139647759361920 basic_session_run_hooks.py:260] loss = 0.021908157, step = 5800 (65.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50559\n",
            "I0705 22:10:09.771264 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50559\n",
            "INFO:tensorflow:loss = 0.041005082, step = 5900 (66.419 sec)\n",
            "I0705 22:10:09.772324 139647759361920 basic_session_run_hooks.py:260] loss = 0.041005082, step = 5900 (66.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51066\n",
            "I0705 22:11:15.967499 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51066\n",
            "INFO:tensorflow:loss = 0.03324096, step = 6000 (66.196 sec)\n",
            "I0705 22:11:15.968513 139647759361920 basic_session_run_hooks.py:260] loss = 0.03324096, step = 6000 (66.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51533\n",
            "I0705 22:12:21.959764 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51533\n",
            "INFO:tensorflow:loss = 0.02791072, step = 6100 (65.992 sec)\n",
            "I0705 22:12:21.960913 139647759361920 basic_session_run_hooks.py:260] loss = 0.02791072, step = 6100 (65.992 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50227\n",
            "I0705 22:13:28.525474 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50227\n",
            "INFO:tensorflow:loss = 0.047176078, step = 6200 (66.566 sec)\n",
            "I0705 22:13:28.526601 139647759361920 basic_session_run_hooks.py:260] loss = 0.047176078, step = 6200 (66.566 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6210 into training/model.ckpt.\n",
            "I0705 22:13:34.487055 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 6210 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:13:37.046714 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:13:38.831217 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:13:38.844268 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:13:38.844655 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:13:39.742723 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:13:39.757558 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:13:41.285872 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:13:41Z\n",
            "I0705 22:13:41.300801 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:13:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:13:41.700372 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:13:41.701064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:13:41.701479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:13:41.701576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:13:41.701602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:13:41.701624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:13:41.701648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:13:41.701670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:13:41.701691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:13:41.701711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:13:41.701834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:13:41.702240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:13:41.702542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:13:41.702584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:13:41.702598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:13:41.702607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:13:41.702731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:13:41.703187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:13:41.703510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-6210\n",
            "I0705 22:13:41.704511 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-6210\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:13:42.808888 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:13:42.982347 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:13:46.061903 139645372360448 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:13:46.062259 139645372360448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:13:46.063654 139645372360448 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:13:46\n",
            "I0705 22:13:46.540975 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:13:46\n",
            "INFO:tensorflow:Saving dict for global step 6210: DetectionBoxes_Precision/mAP = 0.27203786, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.1739155, DetectionBoxes_Precision/mAP@.50IOU = 0.7333261, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.060077075, Loss/BoxClassifierLoss/localization_loss = 0.056154717, Loss/RPNLoss/localization_loss = 0.0449668, Loss/RPNLoss/objectness_loss = 0.019022783, Loss/total_loss = 0.18022136, global_step = 6210, learning_rate = 0.0002, loss = 0.18022136\n",
            "I0705 22:13:46.541303 139647759361920 estimator.py:2049] Saving dict for global step 6210: DetectionBoxes_Precision/mAP = 0.27203786, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.1739155, DetectionBoxes_Precision/mAP@.50IOU = 0.7333261, DetectionBoxes_Precision/mAP@.75IOU = 0.18811882, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.060077075, Loss/BoxClassifierLoss/localization_loss = 0.056154717, Loss/RPNLoss/localization_loss = 0.0449668, Loss/RPNLoss/objectness_loss = 0.019022783, Loss/total_loss = 0.18022136, global_step = 6210, learning_rate = 0.0002, loss = 0.18022136\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6210: training/model.ckpt-6210\n",
            "I0705 22:13:46.544428 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6210: training/model.ckpt-6210\n",
            "INFO:tensorflow:global_step/sec: 1.27622\n",
            "I0705 22:14:46.882005 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.27622\n",
            "INFO:tensorflow:loss = 0.048334856, step = 6300 (78.357 sec)\n",
            "I0705 22:14:46.883271 139647759361920 basic_session_run_hooks.py:260] loss = 0.048334856, step = 6300 (78.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50748\n",
            "I0705 22:15:53.217990 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50748\n",
            "INFO:tensorflow:loss = 0.032864686, step = 6400 (66.336 sec)\n",
            "I0705 22:15:53.219247 139647759361920 basic_session_run_hooks.py:260] loss = 0.032864686, step = 6400 (66.336 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51488\n",
            "I0705 22:16:59.230027 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51488\n",
            "INFO:tensorflow:loss = 0.03197284, step = 6500 (66.012 sec)\n",
            "I0705 22:16:59.230922 139647759361920 basic_session_run_hooks.py:260] loss = 0.03197284, step = 6500 (66.012 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50925\n",
            "I0705 22:18:05.487874 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50925\n",
            "INFO:tensorflow:loss = 0.032768358, step = 6600 (66.258 sec)\n",
            "I0705 22:18:05.488866 139647759361920 basic_session_run_hooks.py:260] loss = 0.032768358, step = 6600 (66.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50411\n",
            "I0705 22:19:11.972358 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50411\n",
            "INFO:tensorflow:loss = 0.034951888, step = 6700 (66.485 sec)\n",
            "I0705 22:19:11.974211 139647759361920 basic_session_run_hooks.py:260] loss = 0.034951888, step = 6700 (66.485 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51672\n",
            "I0705 22:20:17.904133 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51672\n",
            "INFO:tensorflow:loss = 0.020849578, step = 6800 (65.931 sec)\n",
            "I0705 22:20:17.905342 139647759361920 basic_session_run_hooks.py:260] loss = 0.020849578, step = 6800 (65.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51426\n",
            "I0705 22:21:23.942832 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51426\n",
            "INFO:tensorflow:loss = 0.034141846, step = 6900 (66.039 sec)\n",
            "I0705 22:21:23.943941 139647759361920 basic_session_run_hooks.py:260] loss = 0.034141846, step = 6900 (66.039 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5098\n",
            "I0705 22:22:30.176893 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5098\n",
            "INFO:tensorflow:loss = 0.043835856, step = 7000 (66.234 sec)\n",
            "I0705 22:22:30.178220 139647759361920 basic_session_run_hooks.py:260] loss = 0.043835856, step = 7000 (66.234 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7098 into training/model.ckpt.\n",
            "I0705 22:23:34.633449 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 7098 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:23:37.201135 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:23:38.513528 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:23:38.526281 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:23:38.526612 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:23:39.416971 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:23:39.431887 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:23:40.942580 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:23:40Z\n",
            "I0705 22:23:40.957521 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:23:40Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:23:41.389492 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:23:41.390307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:23:41.390706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:23:41.390848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:23:41.390882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:23:41.390902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:23:41.390923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:23:41.390944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:23:41.390964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:23:41.390985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:23:41.391095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:23:41.391502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:23:41.391809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:23:41.391856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:23:41.391871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:23:41.391880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:23:41.391999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:23:41.392402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:23:41.392722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-7098\n",
            "I0705 22:23:41.394041 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-7098\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:23:42.410160 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:23:42.564523 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:23:45.706801 139645372360448 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:23:45.707139 139645372360448 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:23:45.708938 139645372360448 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:23:46\n",
            "I0705 22:23:46.145894 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:23:46\n",
            "INFO:tensorflow:Saving dict for global step 7098: DetectionBoxes_Precision/mAP = 0.25744146, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.1551314, DetectionBoxes_Precision/mAP@.50IOU = 0.6377808, DetectionBoxes_Precision/mAP@.75IOU = 0.18514852, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.33636364, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.0671785, Loss/BoxClassifierLoss/localization_loss = 0.06380336, Loss/RPNLoss/localization_loss = 0.04514516, Loss/RPNLoss/objectness_loss = 0.018961567, Loss/total_loss = 0.19508858, global_step = 7098, learning_rate = 0.0002, loss = 0.19508858\n",
            "I0705 22:23:46.146234 139647759361920 estimator.py:2049] Saving dict for global step 7098: DetectionBoxes_Precision/mAP = 0.25744146, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.1551314, DetectionBoxes_Precision/mAP@.50IOU = 0.6377808, DetectionBoxes_Precision/mAP@.75IOU = 0.18514852, DetectionBoxes_Recall/AR@1 = 0.2, DetectionBoxes_Recall/AR@10 = 0.33636364, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.0671785, Loss/BoxClassifierLoss/localization_loss = 0.06380336, Loss/RPNLoss/localization_loss = 0.04514516, Loss/RPNLoss/objectness_loss = 0.018961567, Loss/total_loss = 0.19508858, global_step = 7098, learning_rate = 0.0002, loss = 0.19508858\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7098: training/model.ckpt-7098\n",
            "I0705 22:23:46.149409 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7098: training/model.ckpt-7098\n",
            "INFO:tensorflow:global_step/sec: 1.2821\n",
            "I0705 22:23:48.173994 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.2821\n",
            "INFO:tensorflow:loss = 0.04886318, step = 7100 (77.997 sec)\n",
            "I0705 22:23:48.175036 139647759361920 basic_session_run_hooks.py:260] loss = 0.04886318, step = 7100 (77.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50012\n",
            "I0705 22:24:54.835179 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50012\n",
            "INFO:tensorflow:loss = 0.038478322, step = 7200 (66.661 sec)\n",
            "I0705 22:24:54.836477 139647759361920 basic_session_run_hooks.py:260] loss = 0.038478322, step = 7200 (66.661 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51661\n",
            "I0705 22:26:00.771747 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51661\n",
            "INFO:tensorflow:loss = 0.014980109, step = 7300 (65.936 sec)\n",
            "I0705 22:26:00.772832 139647759361920 basic_session_run_hooks.py:260] loss = 0.014980109, step = 7300 (65.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51249\n",
            "I0705 22:27:06.887966 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51249\n",
            "INFO:tensorflow:loss = 0.04074695, step = 7400 (66.116 sec)\n",
            "I0705 22:27:06.889144 139647759361920 basic_session_run_hooks.py:260] loss = 0.04074695, step = 7400 (66.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50695\n",
            "I0705 22:28:13.247310 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50695\n",
            "INFO:tensorflow:loss = 0.032443352, step = 7500 (66.359 sec)\n",
            "I0705 22:28:13.248370 139647759361920 basic_session_run_hooks.py:260] loss = 0.032443352, step = 7500 (66.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51063\n",
            "I0705 22:29:19.444963 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51063\n",
            "INFO:tensorflow:loss = 0.04483641, step = 7600 (66.198 sec)\n",
            "I0705 22:29:19.446172 139647759361920 basic_session_run_hooks.py:260] loss = 0.04483641, step = 7600 (66.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50946\n",
            "I0705 22:30:25.693824 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50946\n",
            "INFO:tensorflow:loss = 0.022079779, step = 7700 (66.249 sec)\n",
            "I0705 22:30:25.694977 139647759361920 basic_session_run_hooks.py:260] loss = 0.022079779, step = 7700 (66.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50978\n",
            "I0705 22:31:31.928502 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50978\n",
            "INFO:tensorflow:loss = 0.051462322, step = 7800 (66.235 sec)\n",
            "I0705 22:31:31.929741 139647759361920 basic_session_run_hooks.py:260] loss = 0.051462322, step = 7800 (66.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50664\n",
            "I0705 22:32:38.301342 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50664\n",
            "INFO:tensorflow:loss = 0.030475788, step = 7900 (66.373 sec)\n",
            "I0705 22:32:38.302424 139647759361920 basic_session_run_hooks.py:260] loss = 0.030475788, step = 7900 (66.373 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7987 into training/model.ckpt.\n",
            "I0705 22:33:35.282523 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 7987 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:33:37.956483 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:33:39.287959 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:33:39.300815 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:33:39.301228 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:33:40.189614 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:33:40.205221 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:33:41.713152 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:33:41Z\n",
            "I0705 22:33:41.728660 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:33:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:33:42.171872 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:33:42.172694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:33:42.173145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:33:42.173246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:33:42.173279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:33:42.173303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:33:42.173330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:33:42.173365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:33:42.173388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:33:42.173414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:33:42.173541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:33:42.173978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:33:42.174329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:33:42.174382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:33:42.174407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:33:42.174420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:33:42.174570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:33:42.175002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:33:42.175364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-7987\n",
            "I0705 22:33:42.176611 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-7987\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:33:43.215273 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:33:43.364251 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:33:46.196567 139645258036992 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:33:46.196949 139645258036992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:33:46.198681 139645258036992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.589\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:33:46\n",
            "I0705 22:33:46.644093 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:33:46\n",
            "INFO:tensorflow:Saving dict for global step 7987: DetectionBoxes_Precision/mAP = 0.22911003, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.14341173, DetectionBoxes_Precision/mAP@.50IOU = 0.5893114, DetectionBoxes_Precision/mAP@.75IOU = 0.12376238, DetectionBoxes_Recall/AR@1 = 0.12727273, DetectionBoxes_Recall/AR@10 = 0.3181818, DetectionBoxes_Recall/AR@100 = 0.33636364, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.24444444, Loss/BoxClassifierLoss/classification_loss = 0.07136708, Loss/BoxClassifierLoss/localization_loss = 0.07139225, Loss/RPNLoss/localization_loss = 0.0447649, Loss/RPNLoss/objectness_loss = 0.022000017, Loss/total_loss = 0.20952423, global_step = 7987, learning_rate = 0.0002, loss = 0.20952423\n",
            "I0705 22:33:46.644416 139647759361920 estimator.py:2049] Saving dict for global step 7987: DetectionBoxes_Precision/mAP = 0.22911003, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.14341173, DetectionBoxes_Precision/mAP@.50IOU = 0.5893114, DetectionBoxes_Precision/mAP@.75IOU = 0.12376238, DetectionBoxes_Recall/AR@1 = 0.12727273, DetectionBoxes_Recall/AR@10 = 0.3181818, DetectionBoxes_Recall/AR@100 = 0.33636364, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.24444444, Loss/BoxClassifierLoss/classification_loss = 0.07136708, Loss/BoxClassifierLoss/localization_loss = 0.07139225, Loss/RPNLoss/localization_loss = 0.0447649, Loss/RPNLoss/objectness_loss = 0.022000017, Loss/total_loss = 0.20952423, global_step = 7987, learning_rate = 0.0002, loss = 0.20952423\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7987: training/model.ckpt-7987\n",
            "I0705 22:33:46.648801 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7987: training/model.ckpt-7987\n",
            "INFO:tensorflow:global_step/sec: 1.28811\n",
            "I0705 22:33:55.934388 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.28811\n",
            "INFO:tensorflow:loss = 0.016170058, step = 8000 (77.633 sec)\n",
            "I0705 22:33:55.935271 139647759361920 basic_session_run_hooks.py:260] loss = 0.016170058, step = 8000 (77.633 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51469\n",
            "I0705 22:35:01.954570 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51469\n",
            "INFO:tensorflow:loss = 0.038581673, step = 8100 (66.020 sec)\n",
            "I0705 22:35:01.955510 139647759361920 basic_session_run_hooks.py:260] loss = 0.038581673, step = 8100 (66.020 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51499\n",
            "I0705 22:36:07.961533 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51499\n",
            "INFO:tensorflow:loss = 0.034110174, step = 8200 (66.007 sec)\n",
            "I0705 22:36:07.962896 139647759361920 basic_session_run_hooks.py:260] loss = 0.034110174, step = 8200 (66.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50909\n",
            "I0705 22:37:14.226717 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50909\n",
            "INFO:tensorflow:loss = 0.037609685, step = 8300 (66.265 sec)\n",
            "I0705 22:37:14.227952 139647759361920 basic_session_run_hooks.py:260] loss = 0.037609685, step = 8300 (66.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50901\n",
            "I0705 22:38:20.495551 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50901\n",
            "INFO:tensorflow:loss = 0.038664497, step = 8400 (66.269 sec)\n",
            "I0705 22:38:20.496877 139647759361920 basic_session_run_hooks.py:260] loss = 0.038664497, step = 8400 (66.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50678\n",
            "I0705 22:39:26.862376 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50678\n",
            "INFO:tensorflow:loss = 0.027837118, step = 8500 (66.367 sec)\n",
            "I0705 22:39:26.863706 139647759361920 basic_session_run_hooks.py:260] loss = 0.027837118, step = 8500 (66.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50752\n",
            "I0705 22:40:33.196656 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50752\n",
            "INFO:tensorflow:loss = 0.047708593, step = 8600 (66.334 sec)\n",
            "I0705 22:40:33.198071 139647759361920 basic_session_run_hooks.py:260] loss = 0.047708593, step = 8600 (66.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51117\n",
            "I0705 22:41:39.370512 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51117\n",
            "INFO:tensorflow:loss = 0.037417598, step = 8700 (66.174 sec)\n",
            "I0705 22:41:39.371619 139647759361920 basic_session_run_hooks.py:260] loss = 0.037417598, step = 8700 (66.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50742\n",
            "I0705 22:42:45.708915 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50742\n",
            "INFO:tensorflow:loss = 0.032566212, step = 8800 (66.339 sec)\n",
            "I0705 22:42:45.710400 139647759361920 basic_session_run_hooks.py:260] loss = 0.032566212, step = 8800 (66.339 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8876 into training/model.ckpt.\n",
            "I0705 22:43:35.381450 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 8876 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:43:37.982000 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:43:39.347742 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:43:39.360843 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:43:39.361183 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:43:40.260522 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:43:40.275469 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:43:41.812573 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:43:41Z\n",
            "I0705 22:43:41.827692 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:43:41Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:43:42.246772 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:43:42.247572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:43:42.247981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:43:42.248166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:43:42.248207: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:43:42.248232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:43:42.248255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:43:42.248278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:43:42.248300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:43:42.248322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:43:42.248448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:43:42.248906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:43:42.249225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:43:42.249267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:43:42.249282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:43:42.249292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:43:42.249412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:43:42.249802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:43:42.250133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-8876\n",
            "I0705 22:43:42.251324 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-8876\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:43:43.234047 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:43:43.382277 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:43:46.587099 139645258036992 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:43:46.587486 139645258036992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:43:46.589221 139645258036992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.623\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:43:47\n",
            "I0705 22:43:47.055651 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:43:47\n",
            "INFO:tensorflow:Saving dict for global step 8876: DetectionBoxes_Precision/mAP = 0.2472725, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.14571546, DetectionBoxes_Precision/mAP@.50IOU = 0.6233027, DetectionBoxes_Precision/mAP@.75IOU = 0.15214522, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.069042355, Loss/BoxClassifierLoss/localization_loss = 0.07229614, Loss/RPNLoss/localization_loss = 0.044796128, Loss/RPNLoss/objectness_loss = 0.01923387, Loss/total_loss = 0.20536849, global_step = 8876, learning_rate = 0.0002, loss = 0.20536849\n",
            "I0705 22:43:47.055941 139647759361920 estimator.py:2049] Saving dict for global step 8876: DetectionBoxes_Precision/mAP = 0.2472725, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.14571546, DetectionBoxes_Precision/mAP@.50IOU = 0.6233027, DetectionBoxes_Precision/mAP@.75IOU = 0.15214522, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.34545454, DetectionBoxes_Recall/AR@100 = 0.34545454, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.25555557, Loss/BoxClassifierLoss/classification_loss = 0.069042355, Loss/BoxClassifierLoss/localization_loss = 0.07229614, Loss/RPNLoss/localization_loss = 0.044796128, Loss/RPNLoss/objectness_loss = 0.01923387, Loss/total_loss = 0.20536849, global_step = 8876, learning_rate = 0.0002, loss = 0.20536849\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8876: training/model.ckpt-8876\n",
            "I0705 22:43:47.058782 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8876: training/model.ckpt-8876\n",
            "INFO:tensorflow:global_step/sec: 1.28266\n",
            "I0705 22:44:03.671921 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.28266\n",
            "INFO:tensorflow:loss = 0.02748386, step = 8900 (77.963 sec)\n",
            "I0705 22:44:03.673302 139647759361920 basic_session_run_hooks.py:260] loss = 0.02748386, step = 8900 (77.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50469\n",
            "I0705 22:45:10.130715 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.50469\n",
            "INFO:tensorflow:loss = 0.03298984, step = 9000 (66.459 sec)\n",
            "I0705 22:45:10.131880 139647759361920 basic_session_run_hooks.py:260] loss = 0.03298984, step = 9000 (66.459 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5013\n",
            "I0705 22:46:16.739571 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5013\n",
            "INFO:tensorflow:loss = 0.037630394, step = 9100 (66.609 sec)\n",
            "I0705 22:46:16.740657 139647759361920 basic_session_run_hooks.py:260] loss = 0.037630394, step = 9100 (66.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5083\n",
            "I0705 22:47:23.039234 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5083\n",
            "INFO:tensorflow:loss = 0.04600369, step = 9200 (66.300 sec)\n",
            "I0705 22:47:23.040276 139647759361920 basic_session_run_hooks.py:260] loss = 0.04600369, step = 9200 (66.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51559\n",
            "I0705 22:48:29.019902 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51559\n",
            "INFO:tensorflow:loss = 0.019247219, step = 9300 (65.981 sec)\n",
            "I0705 22:48:29.021147 139647759361920 basic_session_run_hooks.py:260] loss = 0.019247219, step = 9300 (65.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5152\n",
            "I0705 22:49:35.017715 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.5152\n",
            "INFO:tensorflow:loss = 0.031221492, step = 9400 (65.998 sec)\n",
            "I0705 22:49:35.018963 139647759361920 basic_session_run_hooks.py:260] loss = 0.031221492, step = 9400 (65.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51092\n",
            "I0705 22:50:41.202418 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51092\n",
            "INFO:tensorflow:loss = 0.024935184, step = 9500 (66.185 sec)\n",
            "I0705 22:50:41.203638 139647759361920 basic_session_run_hooks.py:260] loss = 0.024935184, step = 9500 (66.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51218\n",
            "I0705 22:51:47.331969 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51218\n",
            "INFO:tensorflow:loss = 0.03180619, step = 9600 (66.130 sec)\n",
            "I0705 22:51:47.333264 139647759361920 basic_session_run_hooks.py:260] loss = 0.03180619, step = 9600 (66.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51336\n",
            "I0705 22:52:53.409933 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.51336\n",
            "INFO:tensorflow:loss = 0.033337593, step = 9700 (66.078 sec)\n",
            "I0705 22:52:53.411086 139647759361920 basic_session_run_hooks.py:260] loss = 0.033337593, step = 9700 (66.078 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9765 into training/model.ckpt.\n",
            "I0705 22:53:35.849213 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 9765 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:53:38.479938 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:53:39.816179 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:53:39.828752 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:53:39.829095 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:53:40.714833 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:53:40.729667 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:53:42.209236 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:53:42Z\n",
            "I0705 22:53:42.224167 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:53:42Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:53:42.640906 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:53:42.641653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:53:42.642053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:53:42.642187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:53:42.642223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:53:42.642254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:53:42.642275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:53:42.642297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:53:42.642317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:53:42.642338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:53:42.642451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:53:42.642852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:53:42.643177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:53:42.643233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:53:42.643247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:53:42.643256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:53:42.643380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:53:42.643764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:53:42.644082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-9765\n",
            "I0705 22:53:42.645284 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-9765\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:53:43.670226 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:53:43.828877 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:53:46.618012 139645258036992 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:53:46.618426 139645258036992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:53:46.619405 139645258036992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.284\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.677\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:53:47\n",
            "I0705 22:53:47.060623 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:53:47\n",
            "INFO:tensorflow:Saving dict for global step 9765: DetectionBoxes_Precision/mAP = 0.28403297, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.19034225, DetectionBoxes_Precision/mAP@.50IOU = 0.67698437, DetectionBoxes_Precision/mAP@.75IOU = 0.19183168, DetectionBoxes_Recall/AR@1 = 0.21818182, DetectionBoxes_Recall/AR@10 = 0.37272727, DetectionBoxes_Recall/AR@100 = 0.37272727, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.2888889, Loss/BoxClassifierLoss/classification_loss = 0.073343836, Loss/BoxClassifierLoss/localization_loss = 0.06693185, Loss/RPNLoss/localization_loss = 0.0450142, Loss/RPNLoss/objectness_loss = 0.021117622, Loss/total_loss = 0.2064075, global_step = 9765, learning_rate = 0.0002, loss = 0.2064075\n",
            "I0705 22:53:47.060902 139647759361920 estimator.py:2049] Saving dict for global step 9765: DetectionBoxes_Precision/mAP = 0.28403297, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.19034225, DetectionBoxes_Precision/mAP@.50IOU = 0.67698437, DetectionBoxes_Precision/mAP@.75IOU = 0.19183168, DetectionBoxes_Recall/AR@1 = 0.21818182, DetectionBoxes_Recall/AR@10 = 0.37272727, DetectionBoxes_Recall/AR@100 = 0.37272727, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.2888889, Loss/BoxClassifierLoss/classification_loss = 0.073343836, Loss/BoxClassifierLoss/localization_loss = 0.06693185, Loss/RPNLoss/localization_loss = 0.0450142, Loss/RPNLoss/objectness_loss = 0.021117622, Loss/total_loss = 0.2064075, global_step = 9765, learning_rate = 0.0002, loss = 0.2064075\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9765: training/model.ckpt-9765\n",
            "I0705 22:53:47.063823 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9765: training/model.ckpt-9765\n",
            "INFO:tensorflow:global_step/sec: 1.28972\n",
            "I0705 22:54:10.946316 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.28972\n",
            "INFO:tensorflow:loss = 0.039789625, step = 9800 (77.536 sec)\n",
            "I0705 22:54:10.947427 139647759361920 basic_session_run_hooks.py:260] loss = 0.039789625, step = 9800 (77.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4979\n",
            "I0705 22:55:17.706583 139647759361920 basic_session_run_hooks.py:692] global_step/sec: 1.4979\n",
            "INFO:tensorflow:loss = 0.03239488, step = 9900 (66.760 sec)\n",
            "I0705 22:55:17.707753 139647759361920 basic_session_run_hooks.py:260] loss = 0.03239488, step = 9900 (66.760 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into training/model.ckpt.\n",
            "I0705 22:56:23.184650 139647759361920 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0705 22:56:25.015285 139647759361920 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:56:25.802531 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:27.184794 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:27.197324 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:56:27.197644 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:28.093209 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:28.109002 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:56:29.673942 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-05T22:56:29Z\n",
            "I0705 22:56:29.688907 139647759361920 evaluation.py:255] Starting evaluation at 2020-07-05T22:56:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0705 22:56:30.124309 139647759361920 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-05 22:56:30.125106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:30.125540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:56:30.125679: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:56:30.125724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:56:30.125750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:56:30.125779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:56:30.125801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:56:30.125825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:56:30.125850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:56:30.125977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:30.126469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:30.126809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:56:30.126879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:56:30.126895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:56:30.126910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:56:30.127040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:30.127476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:30.127839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0705 22:56:30.128942 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0705 22:56:31.113916 139647759361920 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0705 22:56:31.262291 139647759361920 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 7 images.\n",
            "I0705 22:56:34.410269 139645258036992 coco_evaluation.py:237] Performing evaluation on 7 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0705 22:56:34.410621 139645258036992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0705 22:56:34.411810 139645258036992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.684\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-05-22:56:34\n",
            "I0705 22:56:34.870886 139647759361920 evaluation.py:275] Finished evaluation at 2020-07-05-22:56:34\n",
            "INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.2693348, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.17579128, DetectionBoxes_Precision/mAP@.50IOU = 0.6840454, DetectionBoxes_Precision/mAP@.75IOU = 0.15511551, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.36363637, DetectionBoxes_Recall/AR@100 = 0.36363637, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.2777778, Loss/BoxClassifierLoss/classification_loss = 0.07678305, Loss/BoxClassifierLoss/localization_loss = 0.068681546, Loss/RPNLoss/localization_loss = 0.044945456, Loss/RPNLoss/objectness_loss = 0.019118616, Loss/total_loss = 0.20952868, global_step = 10000, learning_rate = 0.0002, loss = 0.20952868\n",
            "I0705 22:56:34.871213 139647759361920 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.2693348, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.67574257, DetectionBoxes_Precision/mAP (small) = 0.17579128, DetectionBoxes_Precision/mAP@.50IOU = 0.6840454, DetectionBoxes_Precision/mAP@.75IOU = 0.15511551, DetectionBoxes_Recall/AR@1 = 0.2090909, DetectionBoxes_Recall/AR@10 = 0.36363637, DetectionBoxes_Recall/AR@100 = 0.36363637, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.75, DetectionBoxes_Recall/AR@100 (small) = 0.2777778, Loss/BoxClassifierLoss/classification_loss = 0.07678305, Loss/BoxClassifierLoss/localization_loss = 0.068681546, Loss/RPNLoss/localization_loss = 0.044945456, Loss/RPNLoss/objectness_loss = 0.019118616, Loss/total_loss = 0.20952868, global_step = 10000, learning_rate = 0.0002, loss = 0.20952868\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n",
            "I0705 22:56:34.874266 139647759361920 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0705 22:56:34.875003 139647759361920 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0705 22:56:35.153894 139647759361920 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:36.458320 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:36.473328 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:56:36.473664 139647759361920 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:37.358366 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:56:37.372810 139647759361920 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0705 22:56:37.984873 139647759361920 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0705 22:56:37.985185 139647759361920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0705 22:56:37.985826 139647759361920 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0705 22:56:37.985945 139647759361920 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0705 22:56:37.986023 139647759361920 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0705 22:56:37.986089 139647759361920 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0705 22:56:37.986165 139647759361920 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-07-05 22:56:37.986723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:37.987128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:56:37.987208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:56:37.987238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:56:37.987257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:56:37.987277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:56:37.987301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:56:37.987322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:56:37.987344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:56:37.987459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:37.987855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:37.988178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:56:37.988219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:56:37.988233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:56:37.988242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:56:37.988355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:37.988734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:56:37.989061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0705 22:56:37.991689 139647759361920 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0705 22:56:38.501485 139647759361920 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0705 22:56:38.501689 139647759361920 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1593989794'/saved_model.pb\n",
            "I0705 22:56:39.336034 139647759361920 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1593989794'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.031309944.\n",
            "I0705 22:56:39.755381 139647759361920 estimator.py:371] Loss for final step: 0.031309944.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "590ec906-3480-4ee4-db36-1e8f835cae4f"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1593982991.bc838dd3314d\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-10000.data-00000-of-00001\n",
            "model.ckpt-10000.index\n",
            "model.ckpt-10000.meta\n",
            "model.ckpt-7098.data-00000-of-00001\n",
            "model.ckpt-7098.index\n",
            "model.ckpt-7098.meta\n",
            "model.ckpt-7987.data-00000-of-00001\n",
            "model.ckpt-7987.index\n",
            "model.ckpt-7987.meta\n",
            "model.ckpt-8876.data-00000-of-00001\n",
            "model.ckpt-8876.index\n",
            "model.ckpt-8876.meta\n",
            "model.ckpt-9765.data-00000-of-00001\n",
            "model.ckpt-9765.index\n",
            "model.ckpt-9765.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79c2714d-8be1-43c3-8c7e-1b1878f6d0a5"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0705 22:57:23.611673 140471783835520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:57:24.920035 140471783835520 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:57:24.934230 140471783835520 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0705 22:57:24.934597 140471783835520 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:166: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0705 22:57:24.983865 140471783835520 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:166: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:428: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0705 22:57:25.598871 140471783835520 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:428: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0705 22:57:26.074426 140471783835520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:57:26.079832 140471783835520 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0705 22:57:26.097672 140471783835520 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0705 22:57:26.671967 140471783835520 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0705 22:57:26.674915 140471783835520 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0705 22:57:26.675900 140471783835520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "204 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.84m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/6.15k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/4.10k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (4, 4/4 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x4, 4.10k/4.10k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/2.05k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (2, 2/2 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x2, 2.05k/2.05k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "204 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.16k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2020-07-05 22:57:28.613779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-05 22:57:28.632441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.632989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:57:28.633313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:57:28.634488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:57:28.645355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:57:28.645713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:57:28.647215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:57:28.653588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:57:28.665276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:57:28.665448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.666100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.666626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:57:28.667147: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-07-05 22:57:28.672580: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-07-05 22:57:28.672787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ffca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-05 22:57:28.672818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-05 22:57:28.765080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.765781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ffc840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-05 22:57:28.765816: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-07-05 22:57:28.766047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.766597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:57:28.766718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:57:28.766748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:57:28.766781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:57:28.766805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:57:28.766828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:57:28.766855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:57:28.766885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:57:28.766996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.767631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.768141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:57:28.768215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:57:28.769396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:57:28.769428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:57:28.769445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:57:28.769596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.770214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:28.770732: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-05 22:57:28.770778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0705 22:57:28.772481 140471783835520 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0705 22:57:30.567431 140471783835520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-07-05 22:57:31.245307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:31.246188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:57:31.246339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:57:31.246373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:57:31.246402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:57:31.246425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:57:31.246451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:57:31.246478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:57:31.246505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:57:31.246660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:31.247544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:31.248305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:57:31.248368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:57:31.248390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:57:31.248407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:57:31.248571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:31.249447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:31.250260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0705 22:57:31.251930 140471783835520 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0705 22:57:31.915533 140471783835520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0705 22:57:31.915790 140471783835520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0705 22:57:32.321901 140471783835520 graph_util_impl.py:334] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0705 22:57:32.434690 140471783835520 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
            "2020-07-05 22:57:32.637825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:32.638420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-05 22:57:32.638510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-07-05 22:57:32.638536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-07-05 22:57:32.638557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-07-05 22:57:32.638577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-07-05 22:57:32.638601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-07-05 22:57:32.638623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-07-05 22:57:32.638642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-05 22:57:32.638755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:32.639350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:32.639829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-07-05 22:57:32.639870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-05 22:57:32.639884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-07-05 22:57:32.639894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-07-05 22:57:32.640010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:32.640595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-05 22:57:32.641086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0705 22:57:33.037835 140471783835520 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0705 22:57:33.038558 140471783835520 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0705 22:57:33.038700 140471783835520 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I0705 22:57:33.374753 140471783835520 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I0705 22:57:33.419846 140471783835520 config_util.py:254] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "527c1465-cb77-47d7-dc6a-d4ceb5a3bf3c"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bf37593-7f0f-4225-ccfd-1830bf6dee9d"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 50M Jul  5 22:57 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw",
        "colab_type": "text"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "209d2ab5-4da6-4958-cc00-d3610f7217e7"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1CT-vNjH93-Dw9TQW5ilnN3gWykYZVUM3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs",
        "colab_type": "text"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f6ab1f8a-c1bf-4ef5-d2b4-f0c58b394225"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9159d237-29b0-43dc-92ac-0433a84ca650\", \"frozen_inference_graph.pb\", 52193067)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS",
        "colab_type": "text"
      },
      "source": [
        "### OPTIONAL: Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq",
        "colab_type": "text"
      },
      "source": [
        "### OPTIONAL: Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pql2QpemazE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnx57Mbe72yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7",
        "colab_type": "text"
      },
      "source": [
        "## Run inference test\n",
        "\n",
        "To test on your own images, you need to upload raw test images to the `test` folder located inside `/data`.\n",
        "\n",
        "Right now, this folder contains TFRecord files from Roboflow. We need the raw images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nE33fiM9WD5",
        "colab_type": "text"
      },
      "source": [
        "#### Add test images to this notebook\n",
        "\n",
        "We can download the exact same raw images that are in our Roboflow test split to our local computer by downloading the images in a different (non-TFRecord) format.\n",
        "\n",
        "Go back to our [dataset](https://public.roboflow.ai/object-detection/bccd/1), click \"Download,\" select \"COCO JSON\" as the format, and download to your local machine.\n",
        "\n",
        "Unzip the downloaded file, and navigate to the `test` directory.\n",
        "![folder](https://i.imgur.com/xkjxmKP.png)\n",
        "\n",
        "\n",
        "Now, on the left-hand side in the colab notebook, select the folder icon.\n",
        "![Colab folder](https://i.imgur.com/59v08qG.png)\n",
        "\n",
        "Right-click on `test`, and select \"Upload.\" Navigate to the files locally on your machine you just downloaded...and voila! You're set!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ENiVg_74Lf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3fbac66d-344d-4127-9ff5-5114d4bea248"
      },
      "source": [
        "# optionally, remove the TFRecord and cells_label_map.pbtxt from\n",
        "# the test directory so it is only raw images\n",
        "%cd {repo_dir_path}\n",
        "%cd data/test\n",
        "%rm cells.tfrecord\n",
        "%rm cells_label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "/content/tensorflow-object-detection-faster-rcnn/data/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1cf77694-1486-4a54-ad8b-89e1bf9b33f8"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00284_jpg.rf.d33fcb37af7c55a50f275711763ddf7a.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00302_jpg.rf.ae0f61c17483b2e0e7f9b1396fc5108c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00062_jpg.rf.e965ee152eea462d82706a2709abfe00.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00359_jpg.rf.e4b6af6691f2d8cc8345f42bcc1678fa.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00227_jpg.rf.1572183909350ffe748751e967b7c8e5.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00336_jpg.rf.5ae87ede3994ca14504136035e256e38.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00112_jpg.rf.f8d86689750221da637a054843c72822.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00154_jpg.rf.7c682b32a64ca0520b6fc725f0d667c7.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00044_jpg.rf.b0e2369642c5a7fa434ed8defa79e2ba.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00133_jpg.rf.06c3705fcfe2fcaee19e1a076e511508.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00325_jpg.rf.55e62842be833601c86a1bd449ee8fe6.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00266_jpg.rf.6d62684a33e2f5bc048803aba3177f58.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00254_jpg.rf.6e046ca48ec2e57c2e178aa3f08ec8ee.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00241_jpg.rf.d0edd8c528bec298a9552ed8ad5714c7.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00334_jpg.rf.3b8a84d57940aeb45e5c2046c8411996.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00235_jpg.rf.b01cbde1f504d448759188feadad4838.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00090_jpg.rf.4fd1da847d2857b6092003c41255ea4c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00038_jpg.rf.63da20f3f5538d0d2be8c4633c7034a1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00337_jpg.rf.7959cb18929c970939cda4a9544547c8.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00278_jpg.rf.9ce9e9760ff20b56b115c86879e02a67.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00160_jpg.rf.500f16e32681898ca1ce052ea0402c08.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00301_jpg.rf.9c427e66bcc1b088df9a5e71c0abefba.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00385_jpg.rf.cf0e48c08597f372423a60918074f574.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00113_jpg.rf.a6d6a75c0ebfc703ecff95e2938be34d.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00289_jpg.rf.58c541d9273174738d3d74e599428169.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00120_jpg.rf.6742a4da047e1226a181d2de2978ce6d.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00386_jpg.rf.1de8e2e0e94f942d7a1523852d7fb146.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00204_jpg.rf.6c3c9e37ab9122b026444cc4e685aef1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00099_jpg.rf.5b178d758af2a97d3df8e5f87b1f344a.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00275_jpg.rf.9108b9a016fadd9c367b05dfb0c40c2c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00369_jpg.rf.99ae139e5530a25980b7acdd56a4317c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00134_jpg.rf.ee0308b1f3e1ffbb048cb3b1f80e8e36.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00265_jpg.rf.4b7cc25caca963b5e0325c6998917cd1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00190_jpg.rf.03484116dcad7715c77d30654056fc54.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00191_jpg.rf.d4b5ad6525c6c0bc4eaea1f24901f396.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00350_jpg.rf.1a19e9f9f197fbeab278718f7c6cea9b.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNFc5CM3Duav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37a1477d-7382-4e77-9b4f-eb69bc104b02"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbKIjbY_MRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output images not showing? Run this cell again, and try the cell above\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah9YKYOX9qrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}